{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pickle\n",
    "'''torch.utils.data    Dataset'''\n",
    "class SnliDataSet(Dataset):\n",
    "    def __init__(self,data,max_premise_id_len=None,max_hypothesis_len=None):\n",
    "        print(len(data[\"premise_id_id\"]))\n",
    "        #序列长度\n",
    "        self.num_sequence=len(data[\"premise_id\"])\n",
    "        #创建tensor矩阵的尺寸\n",
    "        self.premise_id_len=[len(seq) for seq in data[\"premise_id\"]]\n",
    "        self.max_premise_id_len=max_premise_id_len\n",
    "        if self.max_premise_id_len is None:\n",
    "            self.max_premise_id_len=max(self.premise_id_len)\n",
    "        \n",
    "        self.hypothesis_len=[len(seq) for seq in data[\"hypothesis\"]]\n",
    "        self.max_hypothesis_len=max_hypothesis_len\n",
    "        if max_hypothesis_len is None:\n",
    "            self.max_hypothesis_len=max(self.hypothesis_len)\n",
    "#         print(self.num_sequence, self.max_premise_id_len)\n",
    "#         print(self.num_sequence, self.max_hypothesis_len)\n",
    "        #转成tensor，封装到data里\n",
    "        self.data= {\n",
    "            \"premise_id\":torch.zeros((self.num_sequence,self.max_premise_id_len),dtype=torch.long),\n",
    "            \"hypothesis\":torch.zeros((self.num_sequence,self.max_hypothesis_len),dtype=torch.long),\n",
    "            \"labels\":torch.tensor(data[\"labels\"])\n",
    "        }\n",
    "        \n",
    "        for i,premise_id in enumerate(data[\"premise_id\"]):\n",
    "            l=len(data[\"premise_id\"][i])\n",
    "            self.data[\"premise_id\"][i][:l]=torch.tensor(data[\"premise_id\"][i][:l])\n",
    "            l2=len(data[\"hypothesis\"][i])\n",
    "            self.data[\"hypothesis\"][i][:l2]=torch.tensor(data[\"hypothesis\"][i][:l2])\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_sequence\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return { \"premise_id\": self.data[\"premise_id\"][index],\n",
    "                    \"premise_id_len\":min(self.premise_id_len[index], self.max_premise_id_len),\n",
    "                    \"hypothesis\":self.data[\"hypothesis\"][index],\n",
    "                    \"hypothesis_len\":min(self.hypothesis_len[index], self.max_hypothesis_len),\n",
    "                    \"labels\":self.data[\"labels\"][index]   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_id_dir='train_data_id.pkl'\n",
    "f=open(data_train_id_dir,'rb')\n",
    "data_train=pickle.load(f)\n",
    "#for c in data_train.keys():\n",
    " #   print(c)\n",
    "#with open(data_train_id_dir,'rb') as f:\n",
    "train_data=SnliDataSet(data_train,max_premise_len=None,max_hypothesis_len=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pickle.load(f)[\"premise\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
